{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce852be0-5e2b-4262-ad59-81297b8f296f",
   "metadata": {},
   "source": [
    "# Collecting the necessary data\n",
    "Both self-taken images and images from Human Detection Dataset in Kaggle were used in this testing this object detection model. From Human Detection Dataset those images were excluded that include more than one person as the current model is not able to process multiple bounding boxes in one image. Images from Human Detection Dataset have been saved into 'data/images' folder.\n",
    "\n",
    "https://www.kaggle.com/datasets/constantinwerner/human-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468e6cfc-4355-4113-9322-330c4e9e1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25bc85-eca2-4bd0-885d-ffc39c4b1afc",
   "metadata": {},
   "source": [
    "## Take images with webcam\n",
    "OpenCV takes as many images as initialized in the 'number_of_images' variable. Multiple runs of below code should be performed with different clothes and environments etc. so that the data will have more variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb03cd4-c912-43ff-ae2b-6fac468156e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n",
      "Collecting image 15\n",
      "Collecting image 16\n",
      "Collecting image 17\n",
      "Collecting image 18\n",
      "Collecting image 19\n",
      "Collecting image 20\n"
     ]
    }
   ],
   "source": [
    "OPENCV_DIR = '../data/opencv_images'\n",
    "number_of_images = 20\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "for image_num in range(number_of_images):\n",
    "    print('Collecting image {}'.format(image_num + 1))\n",
    "    ret, frame = camera.read()\n",
    "    image_name = f'opencv_frame_{str(uuid.uuid1())}.jpg'\n",
    "    image = os.path.join(OPENCV_DIR, image_name)\n",
    "    cv2.imwrite(image, frame)\n",
    "    time.sleep(0.8)\n",
    "\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca1028b-31f6-49bd-b0f5-382c19ecef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The width of the image is: 640\n",
      "The height of the image is: 480\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(OPENCV_DIR)\n",
    "\n",
    "jpg_files = [file for file in files if file.lower().endswith('.jpg')]\n",
    "\n",
    "if jpg_files:\n",
    "    first_jpg_path = os.path.join(OPENCV_DIR, jpg_files[0])\n",
    "    img = Image.open(first_jpg_path)\n",
    "\n",
    "    img_width = img.width\n",
    "    img_height = img.height\n",
    "\n",
    "    img.close()\n",
    "\n",
    "    print('The width of the image is:', img_width)\n",
    "    print('The height of the image is:', img_height)\n",
    "else:\n",
    "    print('No JPG files found in the specified folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545245d-bb17-4cec-88f5-9574efcfd8b6",
   "metadata": {},
   "source": [
    "## Convert OpenCV images to PNG format\n",
    "Convert images to the same data format as images in the Human Detection Dataset are. Also move them to 'data/images' folder where also the images of Human Detection Dataset are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da483ce7-c63c-45df-9286-831c136290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = '../data/images'\n",
    "\n",
    "for filename in os.listdir(OPENCV_DIR):\n",
    "    image_path = os.path.join(OPENCV_DIR, filename)\n",
    "    image = Image.open(image_path)\n",
    "    # First get file name without file extension and then add .png instead\n",
    "    image_name = f'{Path(image_path).stem}.png'\n",
    "    image.convert('RGB').save(os.path.join(IMAGES_PATH, image_name), 'PNG')\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6be0b1-356d-46f2-9df2-c9668d7fc380",
   "metadata": {},
   "source": [
    "## Label the data\n",
    "Use LabelMe to draw rectangles over the images in 'data/images' folder that have a human in them. Label 'notbuddy' is used. Labels should be stored into 'data/labels' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76e109b-414f-4751-bd24-fed531f96170",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
